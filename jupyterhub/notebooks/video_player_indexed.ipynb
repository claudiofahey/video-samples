{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo Use Case - Queries and Analytics on Video (Part 3)\n",
    "\n",
    "The data scientist now wants to identify video frames in which objects were incorrectly detected.\n",
    "\n",
    "The metadata for the video stream produced by the object detection job is loaded into a Pandas dataframe.\n",
    "This dataframe is used to allow the data scientist to view any image stored in SDP.\n",
    "They can also filter, sort, and aggregate the dataframe using methods that data scientists are familar with.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "See [install_dependencies.ipynb](install_dependencies.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### How to use this Notebook\n",
    "1. Click *Kernel* -> *Restart Kernel and Run All Cells*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "import datetime\n",
    "import time\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "import grpc\n",
    "import imp\n",
    "import pravega.grpc_gateway as pravega\n",
    "import pravega.video as video\n",
    "from pravega.video import UnindexedStream, OutputStream, IndexedStream, opencv_image_to_mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import copy\n",
    "import os\n",
    "\n",
    "imp.reload(video);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Define Pravega stream parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gateway = os.environ['PRAVEGA_GRPC_GATEWAY_ADDRESS']\n",
    "scope = 'examples'\n",
    "#stream = 'object-detector-input-video'\n",
    "stream = 'object-detector-output-video'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Initialize connection to Pravega GRPC Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pravega_channel = grpc.insecure_channel(gateway, options=[\n",
    "        ('grpc.max_receive_message_length', 9*1024*1024),\n",
    "    ])\n",
    "pravega_client = pravega.grpc.PravegaGatewayStub(pravega_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Build timestamp index\n",
    "This is an index from timestamp to begin stream cut, end stream cut, and event pointer.\n",
    "\n",
    "This indexed video player uses the event pointer to fetch frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "imp.reload(video);\n",
    "import pravega.video as video\n",
    "from pravega.video import UnindexedStream, OutputStream, IndexedStream, opencv_image_to_mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "indexed_stream = IndexedStream(pravega_client, scope, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexed_stream.update_index(force_full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "len(indexed_stream.index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_recognitions(recognitions):\n",
    "    return ','.join(np.unique([r['title'] for r in recognitions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "indexed_stream.index_df['recog'] = indexed_stream.index_df.recognitions.apply(clean_recognitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# First and last index record\n",
    "indexed_stream.index_df.iloc[[0,-1]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Video Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PravegaVideoPlayer():\n",
    "    def __init__(self, indexed_stream, figsize=(12,10), \n",
    "                 tz='America/Los_Angeles', strftime='%Y-%m-%d %I:%M:%S.%f %p %z'):\n",
    "        self.indexed_stream = indexed_stream\n",
    "        self.figsize = figsize\n",
    "        self.tz = tz\n",
    "        self.strftime = strftime\n",
    "        self.fields_exclude_cols = ['image_array', 'timestamp', 'to_stream_cut', 'from_stream_cut', 'event_pointer', 'ssrc', 'frameNumber',\n",
    "                                   'chunkIndex', 'finalChunkIndex', 'tags', 'hash', 'recognitions']\n",
    "        \n",
    "    def show(self, frame_number):\n",
    "        video_frame = self.indexed_stream.get_single_video_frame_by_index(frame_number)\n",
    "        timestamp = video_frame['timestamp']\n",
    "        self.timestamp_label.value = '%s  (%s)' % (timestamp, timestamp.astimezone(self.tz).strftime(self.strftime))\n",
    "        self.streamcut_widget.value = video_frame['from_stream_cut']\n",
    "        fields = video_frame.copy()\n",
    "        for col in self.fields_exclude_cols:\n",
    "             if col in fields: del fields[col]\n",
    "        self.fields_widget.value = str(fields.to_dict())\n",
    "        plt.figure(figsize=self.figsize)\n",
    "        plt.imshow(opencv_image_to_mpl(video_frame['image_array']));\n",
    "\n",
    "    def move_to_prev_frame(self):\n",
    "        self.frame_number_widget.value = self.frame_number_widget.value - 1\n",
    "        \n",
    "    def move_to_next_frame(self):\n",
    "        self.frame_number_widget.value = self.frame_number_widget.value + 1\n",
    "    \n",
    "    def interact(self):\n",
    "        w = interactive(\n",
    "            self.show, \n",
    "            frame_number=widgets.IntSlider(\n",
    "                description='Frame',\n",
    "                min=0, \n",
    "                max=len(self.indexed_stream.index_df)-1, \n",
    "                step=1, \n",
    "                value=0,\n",
    "                style={'description_width': 'initial'}))\n",
    "        self.widget = w\n",
    "        self.frame_number_widget = w.children[0]\n",
    "        self.output_widget = widgets.Output()\n",
    "        self.timestamp_label = widgets.Text(description='Timestamp', disabled=True)\n",
    "        self.streamcut_widget = widgets.Text(description='Stream Cut', disabled=True)\n",
    "        self.fields_widget = widgets.Textarea(description='Fields', disabled=True)\n",
    "        \n",
    "        self.play_widget = widgets.Play(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=len(self.indexed_stream.index_df)-1,\n",
    "            step=1,\n",
    "            interval=200,  # milliseconds between frames when playing\n",
    "            description=\"Press play\",\n",
    "            disabled=False\n",
    "        )\n",
    "        widgets.jslink((self.play_widget, 'value'), (self.frame_number_widget, 'value'))\n",
    "        \n",
    "        prev_button = widgets.Button(description=\"<\")\n",
    "        prev_button.on_click(lambda b: self.move_to_prev_frame())\n",
    "        next_button = widgets.Button(description=\">\")\n",
    "        next_button.on_click(lambda b: self.move_to_next_frame())\n",
    "        report_problem_button = widgets.Button(description=\"Report Problem\")\n",
    "        buttons = (prev_button, next_button, report_problem_button)\n",
    "        labels = (self.timestamp_label, self.streamcut_widget, self.fields_widget)\n",
    "        image_widget = w.children[-1]\n",
    "        \n",
    "        w.children = (self.frame_number_widget, self.play_widget) + labels + buttons + (image_widget, self.output_widget)\n",
    "        \n",
    "        layout = w.layout\n",
    "        w.layout.display = 'flex'\n",
    "        w.layout.flex_flow = 'row wrap'\n",
    "        w.layout.justify_content = 'flex-start'\n",
    "        w.layout.align_items = 'flex-start'\n",
    "        self.frame_number_widget.layout.width = '100%'        \n",
    "        for child in labels:\n",
    "            child.layout.width = '100%'\n",
    "        for child in buttons:\n",
    "            child.layout.width = '10%'\n",
    "        image_widget.layout.width = '100%'\n",
    "        self.output_widget.layout.width = '100%'\n",
    "        \n",
    "        display(self.widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "player = PravegaVideoPlayer(indexed_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player for filtered/sorted stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_stream.index_df.camera.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_stream.index_df.recog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(indexed_stream.index_df.groupby(['camera','recog']).size()).unstack().fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = indexed_stream.index_df.copy()\n",
    "#df = df[df.camera==7]\n",
    "#df = df[df.recog!='']\n",
    "#df = df[df.recog.str.contains('person')]\n",
    "#df = df[df.recog.str.contains('boat')]\n",
    "#df = df[df.recog.str.contains('bus,person')]\n",
    "#df = df[df.recog.str.contains('motorbike')]\n",
    "#df = df[df.recog.str.contains('train')]\n",
    "#df = df[df.recog.str.contains('chair')]\n",
    "df = df[df.recog.str.contains('dog')]\n",
    "#df = df[df.recog.str.contains('sofa')]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stream = copy(indexed_stream)\n",
    "filtered_stream.index_df = df\n",
    "player = PravegaVideoPlayer(filtered_stream)\n",
    "player.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Possible Next Steps\n",
    "\n",
    "1. The data scientist may now wish to refine the object detection model based on insights obtained by visualizing the data.\n",
    "2. The data scientist will then deploy the model to SDP as a Flink + TensorFlow job.\n",
    "3. The job will begin inference from the beginning of time or any other position, catch up to the current time, and continue to perform inference on images in near real time.\n",
    "4. The data scientist can use these notebooks to view the results of inference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
